
# stock bot

## 1. 背景与目标（Why）

本项目的目标是：
1) 自动抓取三大交易所的全量股票列表（股票池 / stock universe）。
2) 持续抓取股票交易数据（K 线/成交量/涨跌幅等），形成可复用的数据集。
3) 对股票进行“行为相似性”聚类（clustering），并分析/解释各类股票的起伏趋势特征，辅助投资者做判断。

非目标（当前阶段不做）：
- 不做任何“保证收益”的投资建议；输出应明确为“数据分析与解释”，并带风险提示。
- 不做券商交易下单；仅做数据与分析。

## 2. 数据来源与范围（What）

### 2.1 股票池（必须）
遍历所有证券交易所的股票，从如下网站获取：
- [Shanghai_Stocks](https://www.sse.com.cn/assortment/stock/list/share/)
- [Shenzen_Stocks](https://www.szse.cn/market/stock/deal/index.html)
- [Beijing_Stocks](https://www.bse.cn/nq/listedcompany.html)

需要将股票分类：首先按交易所进行大类划分，之后每个交易所内按“股票类别/板块/类型（以交易所页面可获取的官方分类为准）”进一步分组。

示例结构（仅表达层级，不等同于最终字段）：
```text
Shanghai_Stocks
----class A
----class B
----class C
....
Beijing_Stocks
----class A
----class B
----class C
...
Shenzen_Stocks
----class A
----class B
----class C
...
```

### 2.2 交易数据（必须）
仅靠交易所“股票列表页”通常无法覆盖完整历史行情/分钟级行情，因此需要额外的数据源来获取交易数据（至少日频）。

本 PRD 将“交易数据源”作为可插拔项（Data Provider），允许后续在不改核心分析逻辑的前提下替换数据源。

候选数据源（待选型/确认可用性与合规）：
- 公开行情数据接口（第三方：如 TuShare、AKShare 等）
- 公开网页抓取（需评估页面稳定性、反爬与 ToS）

最低数据要求（字段可扩展）：
- 标识：交易所、股票代码、股票名称
- 日频行情：日期、开/高/低/收、成交量、成交额（若可得）、复权因子（若可得）
- 派生特征：收益率、波动率、回撤、趋势斜率、均线相关指标等

### 2.3 时间范围与频率（建议）
- 回溯：至少近 3 年日频（越长越好，取决于数据源）
- 增量更新：交易日每日收盘后更新（可选：盘中分钟级/5min 级）

## 3. 用户与使用场景（Who）

目标用户：
- 个人投资者：希望快速理解股票“走势风格”和同类对照
- 量化/研究者：希望拿到干净的统一数据与可解释的聚类标签

典型场景：
- 输入“一个股票/一组股票”，系统返回其所在聚类、聚类画像、同类股票、近期趋势摘要
- 浏览“某交易所/某类别”的聚类分布与热点变动

## 4. 核心功能（MVP → v1）

### 4.1 MVP（先跑通一条纵向链路）
1) 抓取一个交易所的股票列表并规范化
2) 为这些股票抓取日频行情（数据源可先选一个）
3) 计算基础特征（收益率/波动率/回撤/趋势）
4) 对股票进行聚类（算法 + 可复现参数）
5) 使用 LLM 对聚类结果做“标签化/解释”（如“高波动趋势股”“稳健震荡股”）
6) 导出结构化结果（JSON/CSV/Parquet 其一即可）

### 4.2 v1（覆盖三大交易所）
- 三大交易所全量股票池抓取与定期更新
- 统一的数据 schema（跨交易所）
- 支持按交易所 + 类别浏览聚类

## 5. 分析方法（How）

### 5.1 特征工程（建议基线）
对每只股票在固定窗口（例如 20/60/120 交易日）计算：
- 收益类：累计收益、区间收益分位
- 风险类：年化波动率、最大回撤、下行波动
- 趋势类：线性回归斜率/拟合优度、均线多头/空头状态、趋势反转次数
- 流动性类：成交量/成交额均值与波动（可得则做）

所有特征需要：
- 明确窗口与计算口径（写入元数据）
- 可复现（同一输入数据应产出同一结果）

### 5.2 聚类（建议基线 + 可扩展）
算法候选：
- KMeans（基线，需选择 K）
- 层次聚类（更易解释）
- DBSCAN/HDBSCAN（发现“异常/稀有模式”）

聚类输入：标准化后的数值特征向量（避免直接喂原始价格序列）。
聚类评估（至少记录）：Silhouette、类内方差、类规模分布。

### 5.3 LLM 的角色（仅做解释与辅助归纳）
LLM 主要用于：
- 对每个 cluster 的统计特征做摘要与命名（labeling）
- 对“某股票 vs 同类”的差异点做解释
- 对趋势变化做自然语言描述

LLM 不直接替代数值计算与聚类算法；输入应尽量是“聚合后的统计摘要”，避免传入大量逐日数据。

输出必须包含：
- 触发 LLM 的输入摘要（可裁剪/脱敏）与版本信息（模型名/时间）
- 免责声明：仅供参考，不构成投资建议

## 6. 输出与交互形态（Deliverables）

第一阶段优先形态：
- CLI（命令行）跑批：抓取 → 计算 → 聚类 → 导出
- 产物文件：
	- 股票池（按交易所/类别分组）
	- 行情数据（按股票/日期）
	- 特征表（按股票/窗口）
	- 聚类结果（按股票/时间戳/版本）
	- 聚类解释（LLM 生成文本 + 引用的统计摘要）

第二阶段可选：
- 简单 Web/Notebook 展示聚类与趋势

## 7. 数据与存储（Engineering）

建议先采用“本地可持久化、易增量”的存储：
- SQLite（元数据/索引/任务状态） + Parquet（大表行情/特征）
或
- 仅 Parquet + 目录分区（exchange=..., symbol=..., date=...）

必须有：
- 任务幂等：重复运行不会产生不一致数据
- 增量更新：只拉取缺失日期
- 速率限制与重试：避免封禁与数据缺口

## 8. 合规与风险（Must）

- 遵守数据源 ToS / robots / 频率限制；对抓取行为做节流。
- 输出中包含风险提示；避免“买入/卖出”式直接建议。
- 若引入第三方 API Key，需要本地环境变量管理，禁止提交到仓库。

## 9. 里程碑（Roadmap）

M0：股票池抓取（单交易所） + 规范化落盘
M1：日频行情抓取（单数据源） + 增量更新
M2：特征工程 + 聚类（可复现）
M3：LLM 聚类解释 + 导出报告
M4：覆盖三大交易所 + 定时任务

## 10. architecture design（待实现时补充）

当开始落地代码后，在此补充：
- 模块边界（fetchers / providers / storage / features / clustering / llm / cli）
- 数据 schema 与版本策略
- 端到端的数据流与依赖关系

## 11. others


